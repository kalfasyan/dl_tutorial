{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import get_label_from_image_path, load_image_array, check_str, train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the directory path for the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"/home/kalfasyan/data/images/fruit/\")\n",
    "# Inside my \"fruit\" folder I have \"Test\" and \"Training\" from the downloaded archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a list of all training data paths and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = list(Path(os.path.join(datadir, 'Training')).rglob('*.jpg'))\n",
    "train_labels = list(map(get_label_from_image_path, train_images)) \n",
    "train_labels = pd.Series(train_labels).apply(lambda x: check_str(x)) # ignore this; I just reduced the number of classes by renaming e.g. Pear 2 => Pear\n",
    "\n",
    "test_images = list(Path(os.path.join(datadir, 'Test')).rglob('*.jpg'))\n",
    "test_labels = list(map(get_label_from_image_path, train_images)) \n",
    "test_labels = pd.Series(test_labels).apply(lambda x: check_str(x)) # ignore this; I just reduced the number of classes by renaming e.g. Pear 2 => Pear\n",
    "\n",
    "nb_classes = train_labels.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking value counts for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.value_counts().plot(kind='bar', figsize=(26,4));\n",
    "plt.title(f\"Number of classes: {nb_classes}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab 25 items randomly and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25 \n",
    "random_idx = np.random.randint(0 , len(train_images), k)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for i, rdm in enumerate(list(random_idx)):\n",
    "    # loading the image\n",
    "    img = load_image_array(str(train_images[rdm]))\n",
    "    # plotting it in a grid 5x5\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(img);\n",
    "    plt.title(train_labels[rdm], y=.95)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training / validation since we already have \"Test\" data in a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# Using strings for the paths for convenience\n",
    "X_train = [str(i) for i in X_train]\n",
    "X_val = [str(i) for i in X_val]\n",
    "# Using lists instead of pandas series for convenience again\n",
    "y_train = y_train.tolist()\n",
    "y_val = y_val.tolist()\n",
    "\n",
    "# Encoding labels to numbers\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making X_test in the same format (list for X and encoded labels for y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [str(i) for i in test_images]\n",
    "y_test = test_labels.tolist()\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(monitor = 'val_loss',\n",
    "                            filepath = 'cnn_basic.h5',\n",
    "                            save_best_only = True,\n",
    "                            save_weights_only = False,\n",
    "                            verbose = 1),\n",
    "                        EarlyStopping(monitor = 'val_loss',\n",
    "                                    patience = 7,\n",
    "                                    verbose = 1),\n",
    "                        ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                    factor = 0.1,\n",
    "                                    patience = 3,\n",
    "                                    verbose = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator(X_train, y_train, batch_size, nb_classes, img_dim=100),\n",
    "                    epochs=30,\n",
    "                    steps_per_epoch = round(len(X_train)/batch_size),\n",
    "                    validation_data=valid_generator(X_val, y_val, batch_size, nb_classes, img_dim=100),\n",
    "                    validation_steps = round(len(X_val)/batch_size),\n",
    "                    callbacks = callbacks_list,\n",
    "                    verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('objdetect': conda)",
   "language": "python",
   "name": "python37864bitobjdetectconda8045af5fdfef4ca9b47f908473881f2a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
